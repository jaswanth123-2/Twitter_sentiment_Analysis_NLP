{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5955a3-adeb-4503-8e6b-1de17275e91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Original dataset: 1,600,000 tweets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing.text_cleaner import TweetCleaner\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../data/raw/training.1600000.processed.noemoticon.csv',\n",
    "                 encoding='latin-1',\n",
    "                 names=['sentiment', 'id', 'date', 'query', 'user', 'text'])\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "print(f\"Original dataset: {len(df):,} tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a33f47-ae60-40c5-a317-f121b3c67a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset: 100,000 tweets\n",
      "Positive: 50,000\n",
      "Negative: 50,000\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE =100000 \n",
    "df_positive = df[df['sentiment']==1].sample(n=SAMPLE_SIZE//2, random_state=42)\n",
    "df_negative = df[df['sentiment']==0].sample(n=SAMPLE_SIZE//2, random_state=42)\n",
    "df = pd.concat([df_positive, df_negative]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Sampled dataset: {len(df):,} tweets\")\n",
    "print(f\"Positive: {(df['sentiment']==1).sum():,}\")\n",
    "print(f\"Negative: {(df['sentiment']==0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6725b95-79d9-4017-8d34-ef567e6f91a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning tweets: 100%|██████████████████████████████████████████████████████| 100000/100000 [00:02<00:00, 40642.65it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaner = TweetCleaner(\n",
    "    lowercase=True,\n",
    "    remove_urls=True,\n",
    "    remove_mentions=True,\n",
    "    remove_hashtags=False,\n",
    "    remove_numbers=False,\n",
    "    remove_emojis=False,\n",
    "    expand_contractions=True\n",
    ")\n",
    "tqdm.pandas(desc=\"Cleaning tweets\")\n",
    "df['text_clean'] = df['text'].progress_apply(cleaner.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c4fda3-82dd-46e4-ac07-527d9e59e2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering bad samples...\n",
      "After filtering: 99,772 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltering bad samples...\")\n",
    "# Remove empty tweets\n",
    "df = df[df['text_clean'].str.strip() != '']\n",
    "# Remove very short tweets (< 3 characters)\n",
    "df = df[df['text_clean'].str.len() >= 3]\n",
    "print(f\"After filtering: {len(df):,} tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6ba3da1-8202-46e5-add5-fcc9553c6524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 79,817\n",
      "Val:   9,977\n",
      "Test:  9,978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['sentiment']\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    random_state=42, \n",
    "    stratify=temp_df['sentiment']\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_df):,}\")\n",
    "print(f\"Val:   {len(val_df):,}\")\n",
    "print(f\"Test:  {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4be496a2-9a2a-4456-8dc4-c7474be67834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Positive: 50.0%\n",
      "Val   - Positive: 50.0%\n",
      "Test  - Positive: 50.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train - Positive: {(train_df['sentiment']==1).sum()/len(train_df)*100:.1f}%\")\n",
    "print(f\"Val   - Positive: {(val_df['sentiment']==1).sum()/len(val_df)*100:.1f}%\")\n",
    "print(f\"Test  - Positive: {(test_df['sentiment']==1).sum()/len(test_df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e31d92-ce48-4d1d-ac9a-e21e90b52e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to data/processed/\n"
     ]
    }
   ],
   "source": [
    "columns_to_save = ['text', 'text_clean', 'sentiment']\n",
    "\n",
    "train_df[columns_to_save].to_csv('../data/processed/train.csv', index=False)\n",
    "val_df[columns_to_save].to_csv('../data/processed/val.csv', index=False)\n",
    "test_df[columns_to_save].to_csv('../data/processed/test.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved to data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2854aef8-7a8e-4eba-9011-ac45c6baf9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 79,817\n",
      "Val samples:   9,977\n",
      "Test samples:  9,978\n",
      "\n",
      "Sample cleaned tweets:\n",
      "\n",
      "Original: @DavidArchie i didn't have the chance to watch your concert  but i get to see all your tv guestings. hope you'll come here again.\n",
      "Cleaned:  i did not have the chance to watch your concert but i get to see all your tv guestings. hope you will come here again.\n",
      "Sentiment: Negative\n",
      "\n",
      "Original: @DaveEHS got 3G on? if so, turn it off \n",
      "Cleaned:  got 3g on? if so, turn it off\n",
      "Sentiment: Positive\n",
      "\n",
      "Original: I better be off and do something productive. \n",
      "Cleaned:  i better be off and do something productive.\n",
      "Sentiment: Positive\n",
      "\n",
      "Original: &quot;But pickle jars are just pickle jars And pickles are just pickles Ingredients : water, salt, cucumber, garlic and pickling spices&quot; \n",
      "Cleaned:  \"but pickle jars are just pickle jars and pickles are just pickles ingredients : water, salt, cucumber, garlic and pickling spices\"\n",
      "Sentiment: Positive\n",
      "\n",
      "Original: @Queensowntalia if you cry a lot , you'll have your first bath in weeks \n",
      "Cleaned:  if you cry a lot , you will have your first bath in weeks\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Train samples: {len(train_df):,}\")\n",
    "print(f\"Val samples:   {len(val_df):,}\")\n",
    "print(f\"Test samples:  {len(test_df):,}\")\n",
    "\n",
    "print(\"\\nSample cleaned tweets:\")\n",
    "for i in range(5):\n",
    "    row = train_df.iloc[i]\n",
    "    print(f\"\\nOriginal: {row['text']}\")\n",
    "    print(f\"Cleaned:  {row['text_clean']}\")\n",
    "    print(f\"Sentiment: {'Positive' if row['sentiment']==1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d79f6-9cc0-42fc-988e-b2e14dbdf0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
